![マイクロソフト クラウド ワークショップ](https://github.com/Microsoft/MCW-Template-Cloud-Workshop/raw/master/Media/ms-cloud-workshop.png "マイクロソフト クラウド ワークショップ")

<div class="MCWHeader1">
Azure Synapse Analytics と AI
</div>
<div class="MCWHeader2">
ホワイトボード設計セッション トレーナー ガイド
</div>
<div class="MCWHeader3">
2020 年 7 月
</div>
このドキュメントに記載されている情報 (URL 等のインターネット Web サイトに関する情報を含む) は、将来予告なしに変更されることがあります。特に断りがない限り、ここで使用している会社、組織、製品、ドメイン名、電子メール アドレス、ロゴ、人物、場所、イベントの例は、架空のものであり、実在する会社、組織、製品、ドメイン名、電子メール アドレス、ロゴ、人物、場所、イベントなどとは一切関係ありません。お客様ご自身の責任において、適用されるすべての著作権関連法規に従ったご使用を願います。このドキュメントのいかなる部分も、米国 Microsoft Corporation の書面による許諾を受けることなく、その目的を問わず、どのような形態であっても、複製または譲渡することは禁じられています。ここでいう形態とは、複写や記録など、電子的な、または物理的なすべての手段を含みます。ただしこれは、著作権法上のお客様の権利を制限するものではありません。

マイクロソフトは、このドキュメントに記載されている内容に関し、特許、特許申請、商標、著作権、またはその他の無体財産権を有する場合があります。別途マイクロソフトのライセンス契約上に明示の規定のない限り、このドキュメントはこれらの特許、商標、著作権、またはその他の無体財産権に関する権利をお客様に許諾するものではありません。

製造元や製品の名前、URL は情報の提供のみを目的としており、マイクロソフトは、これらの製造元、またはマイクロソフトの技術での製品の使用について、明示的、黙示的、または法的にいかなる表示または保証も行いません。製造元または製品の使用は、マイクロソフトによるその製造元または製品の推奨を意味するものではありません。サード パーティのサイトへのリンクが提供されている場合があります。このようなサイトはマイクロソフトの管理下にはなく、マイクロソフトは、リンクされたサイトの内容またはリンクされたサイトに含まれるリンク、あるいはこのようなサイトの変更または更新について責任を負いません。マイクロソフトは、リンクされたサイトから受信された Web キャストまたは他のいかなる形態の転送にも責任を負いません。マイクロソフトは、これらのリンクを便宜のみを目的として提供しており、いかなるリンクの使用も、マイクロソフトによるサイトまたはそこに含まれる製品の推奨を意味するものではありません。

© 2020 Microsoft Corporation.All rights reserved.

Microsoft および <https://www.microsoft.com/en-us/legal/intellectualproperty/Trademarks/Usage/General.aspx> に記載されている商標は、Microsoft グループの商標です。その他すべての商標は、該当する各社が所有しています。

**目次**

<!-- TOC -->

- [トレーナーの情報](#トレーナーの情報)
    - [トレーナーの役割](#トレーナーの役割)
    - [ホワイトボード設計セッションの流れ](#ホワイトボード設計セッションの流れ)
    - [ホワイトボード設計セッション前: 準備方法](#ホワイトボード設計セッション前-準備方法)
    - [ホワイトボード設計セッション中: 効果的なホワイトボード設計セッションのヒント](#ホワイトボード設計セッション中-効果的なホワイトボード設計セッションのヒント)
- [Azure Synapse Analytics と AI ホワイトボード設計セッション受講者ガイド](#azure-synapse-analytics-と-ai-ホワイトボード設計セッション受講者ガイド)
    - [要約と学習目的](#要約と学習目的)
    - [ステップ 1: 顧客のケース スタディの確認](#ステップ-1-顧客のケース-スタディの確認)
        - [顧客の状況](#顧客の状況)
        - [顧客のニーズ](#顧客のニーズ)
        - [顧客の反論](#顧客の反論)
        - [一般的なシナリオのインフォグラフィック](#一般的なシナリオのインフォグラフィック)
    - [ステップ 2: 概念実証ソリューションの設計](#ステップ-2-概念実証ソリューションの設計)
    - [ステップ 3: ソリューションをプレゼンテーションする](#ステップ-3-ソリューションをプレゼンテーションする)
    - [まとめ](#まとめ)
    - [追加リファレンス](#追加リファレンス)
- [Azure Synapse Analytics と AI ホワイトボード設計セッション トレーナー ガイド](#azure-synapse-analytics-と-ai-ホワイトボード設計セッション-トレーナー-ガイド)
    - [ステップ 1: 顧客のケース スタディの確認](#ステップ-1-顧客のケース-スタディの確認-1)
    - [ステップ 2: 概念実証ソリューションの設計](#ステップ-2-概念実証ソリューションの設計-1)
    - [ステップ 3: ソリューションをプレゼンテーションする](#ステップ-3-ソリューションをプレゼンテーションする-1)
    - [まとめ](#まとめ-1)
    - [推奨される対象者](#推奨される対象者)
    - [推奨ソリューション](#推奨ソリューション)
    - [反論への推奨される対応のチェックリスト](#反論への推奨される対応のチェックリスト)
    - [顧客の声 (最後に出席者に対して読み上げる)](#顧客の声-最後に出席者に対して読み上げる)

<!-- /TOC -->
# トレーナーの情報

トレーナーとしてホワイトボード設計セッションをサポートするためにお時間を割いていただき誠にありがとうございます。

## トレーナーの役割

優れたトレーナーとは

- 安全に学習できる環境を構築します。

- 参加者の思考を刺激します。

- 参加者を学習プロセスに関与させます。

- 学習プロセスを管理します (時間どおりに、トピックに従って、参加者がメリットを得られるように調整します)。

- 個々の参加者の責任を徹底します。

- 参加者のためにすべてをまとめます。

- 学習プロセスへの洞察と経験を提供します。

- ホワイトボード設計セッションの議論を効果的に主導します。

- 参加者の成果物の品質と妥当性を監視します。

- フィードバック プロセスを効果的に主導します。

## ホワイトボード設計セッションの流れ

各ホワイトボード設計セッションは、次の流れで行います。

**ステップ 1: 顧客のケース スタディの確認 (15 分)**

**成果**

顧客のニーズを分析する。

- 顧客の背景、状況、ニーズ、および技術的な要件

- 顧客の現在のインフラストラクチャとアーキテクチャ

- 潜在的な問題、反論、および阻害要因

**ステップ 2: 概念実証ソリューションの設計 (60 分)**

**成果**

ソリューションを設計し、そのソリューションを 15 分のチョークトーク形式で顧客の対象者にプレゼンテーションする準備をする。

- 顧客の対象者を決定する。

- 顧客のビジネス ニーズを判断してソリューションに取り組む。

- ソリューションを設計して図で表す。

- ソリューションのプレゼンテーションを準備する。

**ステップ 3: ソリューションのプレゼンテーション (30 分)**

**成果**

ソリューションを顧客にプレゼンテーションする。

- ソリューションをプレゼンテーションする

- 顧客の反論に回答する

- フィードバックを受ける

**まとめ (15 分)**

- 推奨ソリューションを確認する

## ホワイトボード設計セッション前: 準備方法

最初のホワイトボード設計セッションを実施する前に、以下を行います。

- 受講者ガイド (ケース スタディを含む) およびトレーナー ガイドを読む。

- すべてのキー ポイントとアクティビティを十分に理解する。

- 強調したいポイント、どの質問を活発化させたいか、および進め方を計画し、質問に回答する準備をする。

- ホワイトボード設計セッションの前に、ケース スタディについて議論してさらにアイデアを集める。

- 後で参照するためにメモを取る。

## ホワイトボード設計セッション中: 効果的なホワイトボード設計セッションのヒント

**トレーナー ガイドを参照して**、セッションを円滑に進め、時間を守る。

ホワイトボード設計セッションの**詳細をすべて覚えようとしない**。

参加者がアクティビティを実施しているときに、**次に何を行うかを考えて、覚えていることを確認する**。

- 必要に応じて、**アクティビティとホワイトボード設計セッションのペースを調整して**、プレゼンテーション、フィードバック、および共有の時間を設ける。

- 自身の経験から、**例、ポイント、および事例を追加する**。 共有できる事例の中から、ポイントを明確かつ効果的に伝えるのに役立つものがないか考えます。

- ホワイトボード設計セッションのスコープ外で発生した問題や疑問、または後で回答できる問題や疑問を記録する **"パーキング ロット" を設けることを検討する**。これらの問題をどのように解決するかを判断し、脱線することなく問題を確認できるようにします。

**楽しむ**。楽しんで共有するよう参加者に促します。

**参加者を関与させる**。話をして自身の知識を共有しますが、自分が話している間も常に参加者を関与させます。

グループを十分に学習プロセスに関与させるために、**質問をして**その内容を共有します。

可能な限り、**最初に質問から入る**。トピックを始める前に、そのトピックに関する対象者の意見と経験について学びます。最初に質問から入ることにより、対象者の知識と経験のレベルを評価し、対象者がプレゼンテーションの内容に対してオープンな姿勢を保つことができます。

**反応を待つ**。"(空欄に記入) についてどのような経験がありますか" のような質問をして、反応を待ちます。多少の沈黙は気にしないでください。こちらから沈黙を破ると、参加者を真剣には関与させようとしていないのではないかという印象を与え、参加者は受け身になってしまいます。参加者に考えるチャンスを与え、誰も答えない場合は、辛抱強くもう一度質問します。通常は反応があります。

# Azure Synapse Analytics と AI ホワイトボード設計セッション受講者ガイド

## 要約と学習目的

このホワイトボード設計セッションでは、グループを作って、Azure Synapse Analytics を使用してエンドツーエンドのソリューションを設計するプロセスを見ていきます。設計セッションでは、データ読み込み、データ準備、データ変換、およびデータ サービスについて説明し、機械学習の実行およびバッチ データとリアルタイム データの両方の処理についても説明します。

このホワイトボード設計セッションを完了すると、Azure Synapse Analytics を使用する完全なエンドツーエンドの高度な分析ソリューションを設計および構築できるようになります。

## ステップ 1: 顧客のケース スタディの確認

**成果**

顧客のニーズを分析する。

所要時間: 15 分

指示: セッションの参加者全員と共に、ファシリテーター/SME は、顧客のケース スタディの概要を技術的なヒントと併せてプレゼンテーションします。

1. テーブルの参加者およびトレーナーと打ち合わせを行います。

2. 受講者ガイドのステップ 1 ～ 3 の指示をすべて読みます。

3. テーブル チームとして、次の顧客のケース スタディを確認します。

### 顧客の状況

Wide World Importers (WWI) は、数百軒の実店舗とオンライン ストアを展開し、さまざまな製品を販売しています。

WWI は、データは小売業にとって "酸素" のようなものであると信じています。これまで小売業ではデータが不足することはありませんでしたが、WWI はこのデータの価値を最大限に活かすことができていませんでした。彼らは、断片化されたデータや顧客の行動や期待についての理解不足に悪戦苦闘していますが、カスタマー エクスペリエンス戦略を成功させるにはデータを効果的に使用することが不可欠であると信じています。

WWI は、小売データに分析を加えることで、見込み顧客および既存の顧客をその購買ジャーニーを通じて魅了する、パーソナライズされたオムニチャネル キャンペーンを改善する方法が明らかになる可能性があることを理解しています。

WWI は、顧客データ、運用データ、調達およびサプライヤー データ、取引データなど小売業のライフサイクル データに分析を組み合わせることによって、顧客離れの抑制、ロイヤルティの強化、カスタマー ジャーニーの向上、コンテクスト マーケティング実施能力の獲得、アトリビューションの測定を実現し、組織全体の成長を包括的に推進する企業全体にわたる洞察を提供することを望んでいます。

そのために、これまでのキャンペーンと顧客の分析データを使用して、現在について意思決定しようとしています。それらの大量のこれまでのデータ セット以外に、Twitter からのストリーミング ツイート データおよび実店舗の IoT センサーからのテレメトリを使用したいと考えています。実際に、今の瞬間に得たデータを利用して、次の瞬間のための意思決定に情報を提供したいと考えています。WWI は、まずは商品レコメンデーションを行うことによって、データから将来を予測する機会を見出します。

最高技術責任者 (CTO) の Peter Guerin 氏によれば、Wide World Importers では、Oracle に 300 億行を超える、5 年以上にわたる販売トランザクション データが保存されています。しかし、同社の企業データ ソースはそれだけではありません。SAP HANA に財務データ、Teradata にマーケティング データがそれぞれ保存され、さらに Twitter からソーシャル メディア データを取り込んでいます。必要なのは、これらのすべてのソースのデータを統合し、クエリを実行し、分析できるソリューションです。また、どんなに量が多くても、それらのデータに対してクエリを実行してから数秒以内に結果を得られることを望んでいます。

前述のデータ ソースに加えて、通路を歩く顧客の移動パターンを追跡するテレメトリ データを生成する店舗内 IoT センサーがあります。100 軒の店舗があり、店舗あたり 50 個のセンサーがリアルタイム データを提供します。このデータを使用して、人々がほとんどの時間を過ごしているのはどの売り場 (または通路群) で、ほとんど滞在しないのはどの売り場かを把握したいと考えています。このデータをほぼリアルタイムに取り込んで処理し、速やかにパターンを特定して店舗間で共有できるようにするソリューションを必要としています。たとえば、東海岸の店舗が開店したときの早い時間の購買行動で検出したパターンから、閉店前のセールや、開店前の西海岸の店舗での店内商品の配置替えに役立つ知識を得られる可能性があります。

WWI は、社内の専門家が、コードを作成して、または作成しないで、データの取り込みとデータの変換のパイプラインを作成できるようにするオプションを望んでいます。彼らはこれを実現するために、グラフィカル デザイナーを使用してそれらの変換パイプラインを容易に構築できるようにするツールを使用することと、彼らのチームが希望する場合はコードでそれを実装できるようにすることを望んでいます。WWI によって革新的とみなされるのは、彼らの製品コストを自動的に最新の状態に保つパイプラインでしょう。WWI は、サプライヤーによって提供される請求書を取得することができれば、部品とコストを抽出し、ダウンストリームにおける収益性の計算のためにデータ ウェアハウスでこれらのデータを更新できると考えています。

Guerin 氏は、自身の経験から、ツールに対する不満点は、予備調査のデータ分析をする前に必要なセットアップ作業量にあるとも述べています。そのため、WWI が取り込んだ生データを速やかに調査してその内容を理解できるソリューションを望んでいます。

Wide World Importers は、業務の全体像を把握するために、履歴データ、リアルタイムの Twitter センチメント、および IoT センサー データから導出した主要業績評価指標 (KPI)、さらに機械学習を使用して生成した主要商品レコメンデーションを確認できるダッシュボードの作成を必要としています。

### 顧客のニーズ

1. 履歴分析、リアルタイム分析、および予測分析を組み合わせてビジネスの洞察を得ること。

2. 構造化データ ソースと非構造化データ ソースを処理する統合アプローチを実現すること。

3. データ エンジニアとデータ サイエンティストから成るチームが、数ペタバイトに及ぶ数十億行の構造化データと企業業務の非構造化データに対する複雑なクエリを導入して実行できること。

4. ビジネス アナリストとデータ サイエンス/データ エンジニアリング チームが信頼できる唯一の情報源を共有できること。

5. 取り込み、変換、クエリ、および保存を行う際に使用する異種サービスの数を最小限に抑えて、データ エンジニア、データ サイエンティスト、およびデータベース管理者のチームが、1 つのツールを習得し、開発、管理、および監視を行うための共有ベスト プラクティスを構築できること。

6. 1 つのコラボレーション環境内で作業すること。

7. パフォーマンス上の懸念から、必ず、ソリューションの最高のパフォーマンスを達成するための中核となるアプローチが十分に理解されるようにすること。

8. すべてのコンポーネントにわたって一貫したセキュリティ モデルを提供するソリューションを作成すること。

### 顧客の反論

1. WWI は、Azure が提供するいくつかのサービスでは機能が重複していることを把握しています。望んでいる分析ソリューションになるように、時間をかけてそれらを調整したいとは考えていません。

2. 大量のデータセットを数秒以内で読み込むと主張する競合システムのデモを見たことがあります。Azure ではそのようなソリューションを提供していますか。

3. 取り込み、変換、クエリ、および保存を行う際に使用する異種サービスの数を最小限に抑えて、WWI のデータ エンジニア、データ サイエンティスト、およびデータベース管理者から成るチームが、1 つのツールを習得し、開発、管理、および監視を行うための共有ベスト プラクティスを構築できるようにすることが本当に可能ですか。

4. サーバーレス クエリのことを聞いたことがありますが、Azure では提供していますか。それは WWI が持つ規模のデータのクエリに対応できますか。どの形式をサポートしていますか。WWI のダッシュボードやレポートをサポートするのに適していますか。

5. Azure がサーバーレス クエリをサポートしている場合、サーバーレスを選択すると、事前に割り当てたクエリ リソースを使用するオプションは削除されますか。

6. 保存時のデータは保護されますか。データの暗号化に使用した鍵の管理は行われますか。

7. Azure Databricks と Azure Synapse Analytics は機能が重複しているように見えますが、何を基準にして選択するのですか。

8. Azure は、クライアント アプリケーションから簡単に呼び出すことができるように、Web サービスとしてのモデルの展開をどのようにサポートしていますか。

9. Azure において、モデルの再トレーニング プロセスはどのように実行されますか。WWI のデータ サイエンティストは、新しいモデルをトレーニングし、評価する一方で、アプリケーションに更新を展開するために使用される DevOps プロセスに、どのようにこの再トレーニングを確実に組み込むことができますか。Azure は、クライアント アプリケーション、機械学習 API、およびその API を支援するモデルに対する更新を調整するために役立ちますか。

### 一般的なシナリオのインフォグラフィック

![Azure Synapse Analytics の機能の概要。Azure Synapse Studio によるユーザー エクスペリエンス、SQL と Spark によるデータ処理用プラットフォーム、およびデータ レイクの統合管理を提供するソリューションの構成が示されています。](media/infographic.png "Azure Synapse Analytics の概要")

## ステップ 2: 概念実証ソリューションの設計

**成果**

ソリューションを設計し、そのソリューションを 15 分のチョークトーク形式で顧客の対象者にプレゼンテーションする準備をする。

所要時間: 60 分

**ビジネス ニーズ**

指示: テーブルのすべての参加者と共に以下の質問に回答し、回答をフリップ チャートに一覧にします。

1. このソリューションを誰にプレゼンテーションするべきか。顧客の対象者は誰か。意思決定者は誰か。

2. ソリューションで解決する必要がある顧客のビジネス ニーズは何か。

**設計**

指示: テーブルのすべての参加者と共に、フリップ チャートの次の質問に回答します。

アーキテクチャの概要

1. データ読み込み、データ変換、ストレージ、機械学習モデリング、およびレポートの最上位の要件に対応するための初期ビジョンを図示します。

取り込みと保存

1. 推奨するソリューションについて、フラット ファイル データを取り込んで保存した場所からデータ レイクに移動する場合に最も効率的なのは、具体的にはどのアプローチだと WWI に伝えますか。

2. どのストレージ サービスを使用するように勧めますか。さまざまな洗練レベルでデータを管理できるようにするために、どのようにフォルダーを構造化することを勧めますか。

3. 新しいデータ ソースからバッチで生データを取り込む場合、ソリューションではどのデータ形式をサポートできますか。

4. 店舗内 IoT デバイスからのストリーミング データをどのように取り込みますか。

変換

1. 生データを取り込んだ後、変換パイプラインを構築する前またはそれをデータ ウェアハウスに読み込む前に、WWI はどのようにして速やかにその生データを調査してその内容を理解できるのでしょうか。

2. 洗練したバージョンのデータをクエリできるように保存する場合、どのデータ形式を使用することを勧めますか。それはなぜですか。

3. データの準備、マージ、および変換に使用するように勧めるサービスについて、どの状況でグラフィカル デザイナーを使用できて、どの状況でコードを作成する必要がありますか。

4. WWI のデータ チームは、データの速やかな前処理と、データ サイエンティストによる Spark と Python の両方を使用した機械学習モデルのトレーニングを可能にするオープン ソース パッケージを利用することに慣れています。マイクロソフトのソリューションでそれを実現する方法を説明してください。

5. マイクロソフトのソリューションでは、WWI のデータ エンジニアとデータ サイエンティストが Jupyter ノートブック内で作業できますか。ライブラリをどのように管理しますか。

6. このソリューションは、サプライヤーの請求書によって、データ ウェアハウス内の部品コスト テーブルを常に更新する必要性にどのように対応しますか。

クエリ

WWI の販売トランザクション データセットは 10 億行を超えています。ダウンストリームのレポート クエリのために、これらの行を数十秒以内で結合、射影、およびフィルターできるようにする必要があります。WWI は、これを実現するにはあまりにデータが多すぎることを懸念しています。

1. ファクト テーブルで前述のパフォーマンスを達成するには、具体的にどのインデックス作成手法を使用する必要がありますか。それはなぜですか。

2. 1 億行未満のテーブルにも同じアプローチを勧めますか。

3. 小規模なルックアップ テーブル (店舗の名称や住所が保存されているテーブルなど) のインデックスはどのように構成する必要がありますか。

4. 1 行のみを取得するポイント ルックアップにのみ使用する大規模なルックアップ テーブルにはどんなことを提案しますか。複数のクエリがフィルタリングする列が異なっていても効率的にルックアップできるように、大規模なルックアップ テーブルの柔軟性を高めるにはどうすればいいですか。

5. ステージング テーブルの読み込みを最も速くするには、何を使用する必要がありますか。

6. 以下に示すシナリオでの**分散**テーブル設計に関して注意する必要がある典型的な問題には何がありますか。
   
   - 最も小さいファクト テーブルが数 GB を超えていて、本質的に挿入が頻繁に行われます。
   
   - WWI のデータ チームは、データ ウェアハウスを開発する際に生の入力データから役に立つかもしれないテーブルをいくつか作成しましたが、現在それらのテーブルは他のテーブルと結合されておらず、データ分散に使用するのに最適な列も不明です。
   
   - WWI のデータ エンジニアは、データを準備する際に、一時ステージング テーブルを使用することがあります。
   
   - 数百 MB から 1.5 GB までの規模のルックアップ テーブルがあります。

7. データの一部に JSON 形式の列が含まれています。どうすればこれらの階層フィールドを表形式構造に平坦化できますか。

8. JSON データを更新するのにどんなアプローチを使用できますか。

9. WWI は、一部のクエリでは、結果を返す時間を短縮できるのであれば、精度が多少落ちるのは構わないと考えています。どうすればそれを実現できますか。

10. ダウンストリームのレポートは多数のユーザーが使用します。これは多くの場合、それほど頻繁に変化しないデータに対して同じクエリが繰り返し実行されることを意味します。何を使用すると、このようなタイプのクエリのパフォーマンスを高めることができますか。基礎となるデータが変化する場合、このアプローチはどのように機能しますか。

可視化

1. WWI は、どの製品を使用すると、小売トランザクション データを可視化できますか。それはインストールする必要がある独立したツールですか。

2. その同じツールを使用して、バッチ データとストリーミング データの両方を 1 つのダッシュボード画面で可視化できますか。

3. 推奨する製品を使用する場合、データを参照するレポートを作成する前に、すべてのデータをデータ ウェアハウスに読み込む必要がありますか。

管理

1. これまで、WWI のシステムはユーザーに人気がありませんでした。時間的制約のない調査クエリが使用可能なリソースを飽和状態にして、重要なレポートを作成するための優先度の高いクエリの実行を遅らせていました。推奨するソリューションがこれを解決するのにどのように役立つのか説明してください。

2. 推奨するソリューションは、テーブル分散が最適ではない、データ スキュー、キャッシュ ミス、tempdb 競合、プラン選択が最適ではないなどの問題を WWI が検出するのを支援するために何を提供しますか。

3. WWI は、データ ウェアハウス ソフトウェアを最新の状態に保つには、それに伴うダウンタイムを許容できるタイミングを決める必要があることを理解しています。推奨するソリューションでは、どうすれば WWI は予期しないアップグレードに慌てることのない設定を確立できますか。

安全性

1. 推奨するソリューションは、たとえば SQL と Spark のワークロードに対して、どのようにして統合された認証を提供しますか。

2. Azure Data Lake Store Gen2 に保存されているデータに対するデータ アクセスをどのように承認しますか。Azure Synapse SQL データベースに保存されているデータについてはどうですか。

3. WWI の課題の 1 つは、複数の部門が特定のテーブルに対するクエリを実行できる可能性がある一方で、各自にどのデータの表示が許可されるのかは部門または社内での役割によって決まることです。推奨するソリューションでは、これをどのようにサポートできますか。3 つの選択肢を提案する必要があります。

4. そのソリューションは、WWI がセキュリティの構成ミスを検出、追跡、および修復し、脅威を検出するのに役立ちますか。どんな方法ですか。

5. WWI はこのソリューションを使用して、機密情報を検出、分類、および保護し、機密情報へのアクセスを追跡できるようにすることで、機密情報を監視できますか。

6. ネットワーク セキュリティの観点から、推奨するソリューションをどのように保護する必要がありますか。

**準備**

指示: テーブルのすべての参加者と共に、以下を行います。

1. 提案したソリューションでは対応していない顧客ニーズを特定する。

2. ソリューションの利点を特定する。

3. 顧客の反論にどのように回答するかを決定する。

顧客に対する 15 分のチョークトーク形式のプレゼンテーションを準備する。

## ステップ 3: ソリューションをプレゼンテーションする

**成果**

顧客の対象者にソリューションを 15 分のチョークトーク形式でプレゼンテーションする。

所要時間: 30 分

**プレゼンテーション**

指示:

1. 別のテーブルとペアを組む。

2. 一方のテーブルはマイクロソフト チーム、他方のテーブルは顧客とする。

3. マイクロソフト チームは提案ソリューションを顧客にプレゼンテーションする。

4. 顧客は反論リストから反論を 1 つ行う。

5. マイクロソフト チームは反論に回答する。

6. 顧客チームはマイクロソフト チームにフィードバックを提供する。

7. テーブル間で役割を切り替えて、ステップ 2 ～ 6 を繰り返す。

## まとめ

所要時間: 15 分

指示: より大きなグループでテーブルに再度集まり、ファシリテーター/SME がこのケース スタディの推奨ソリューションを共有するのを聞きます。

## 追加リファレンス

|                               |                                                                                                |
|-------------------------------|------------------------------------------------------------------------------------------------|
| **説明** | **リンク** |
| Azure Synapse Analytics とは| https://docs.microsoft.com/en-us/azure/synapse-analytics/sql-data-warehouse/sql-data-warehouse-overview-what-is
| Azure Synapse Analytics ソリューションの早見表| https://docs.microsoft.com/en-us/azure/synapse-analytics/sql-data-warehouse/cheat-sheet
| Azure Synapse Analytics の FAQ| https://docs.microsoft.com/en-us/azure/synapse-analytics/sql-data-warehouse/sql-data-warehouse-overview-faq
| Azure SQL Database の高度なデータ セキュリティ| https://docs.microsoft.com/en-us/azure/sql-database/sql-database-advanced-data-security?toc=/azure/synapse-analytics/sql-data-warehouse/toc.json\&bc=/azure/synapse-analytics/sql-data-warehouse/breadcrumb/toc.json
| Azure SQL DB および Data Warehouse のプライベート リンク| https://docs.microsoft.com/en-us/azure/sql-database/sql-database-private-endpoint-overview?toc=/azure/synapse-analytics/sql-data-warehouse/toc.json\&bc=/azure/synapse-analytics/sql-data-warehouse/breadcrumb/toc.json
| 列レベルのセキュリティ| https://docs.microsoft.com/en-us/azure/synapse-analytics/sql-data-warehouse/column-level-security
| 行レベルのセキュリティ| https://docs.microsoft.com/en-us/sql/relational-databases/security/row-level-security?toc=%2Fazure%2Fsynapse-analytics%2Fsql-data-warehouse%2Ftoc.json\&bc=%2Fazure%2Fsynapse-analytics%2Fsql-data-warehouse%2Fbreadcrumb%2Ftoc.json\&view=sql-server-ver15
| 動的データ マスク| https://docs.microsoft.com/en-us/azure/sql-database/sql-database-dynamic-data-masking-get-started?toc=%2Fazure%2Fsynapse-analytics%2Fsql-data-warehouse%2Ftoc.json\&bc=%2Fazure%2Fsynapse-analytics%2Fsql-data-warehouse%2Fbreadcrumb%2Ftoc.json\&view=sql-server-ver15
| Transparent Data Encryption| https://docs.microsoft.com/en-us/azure/sql-database/transparent-data-encryption-azure-sql?toc=%2Fazure%2Fsynapse-analytics%2Fsql-data-warehouse%2Ftoc.json\&bc=%2Fazure%2Fsynapse-analytics%2Fsql-data-warehouse%2Fbreadcrumb%2Ftoc.json\&view=sql-server-ver15\&tabs=azure-portal
| JSON 関数| https://docs.microsoft.com/en-us/sql/t-sql/functions/json-functions-transact-sql?toc=%2Fazure%2Fsynapse-analytics%2Fsql-data-warehouse%2Ftoc.json\&bc=%2Fazure%2Fsynapse-analytics%2Fsql-data-warehouse%2Fbreadcrumb%2Ftoc.json\&view=sql-server-ver15
| 結果セットのキャッシュ| https://docs.microsoft.com/en-us/azure/synapse-analytics/sql-data-warehouse/performance-tuning-result-set-caching?view=sql-server-ver15
| Synapse Analytics のテーブルの概要| https://docs.microsoft.com/en-us/azure/synapse-analytics/sql-data-warehouse/sql-data-warehouse-tables-overview?view=sql-server-ver15
| ワークロード管理| https://docs.microsoft.com/en-us/azure/synapse-analytics/sql-data-warehouse/sql-data-warehouse-workload-management?view=sql-server-ver15
| Azure Data Lake Store Gen2 の概要| https://docs.microsoft.com/en-us/azure/storage/blobs/data-lake-storage-introduction
| Azure Stream Analytics| https://docs.microsoft.com/en-us/azure/stream-analytics/stream-analytics-introduction

# Azure Synapse Analytics と AI ホワイトボード設計セッション トレーナー ガイド

## ステップ 1: 顧客のケース スタディの確認

- テーブルの参加者に会い、自身をトレーナーとして自己紹介する。

- "顧客のケース スタディについてどのような質問があるか" と尋ねる。

- ホワイトボード設計セッションのステップと所要時間を簡単に確認する。

- 準備が整ったら、テーブルの参加者に開始させる。

## ステップ 2: 概念実証ソリューションの設計

- テーブルを回り、各ステップが時間どおりに進んでいることを確認する。

- ビジネス ニーズと設計への回答について何らかのフィードバックを提供する。
  
  - 最初に、参加者が自分自身で回答を見つけやすくなるような質問をしてみる。

- 顧客の反論への回答にフィードバックを提供する。
  
  - 最初に、参加者が自分自身で回答を見つけやすくなるような質問をしてみる。

## ステップ 3: ソリューションをプレゼンテーションする

- ステップ 3 の開始前に、どのテーブルが自分のテーブルとペアを組むかを決定する。

- 1 回目では、一方のテーブルをプレゼンテーション チームとして割り当て、他方を顧客として割り当てる。

- プレゼンテーション チームがそのソリューションを顧客チームにプレゼンテーションする。
  
  - プレゼンテーション チームが回答すべき反論を、顧客チームから 1 つ提供する。
  
  - プレゼンテーション、反論、およびフィードバックは 15 分以内に収める必要がある。
  
  - 必要に応じて、トレーナーもフィードバックを提供できる。

## まとめ

- より大きなセッション グループにテーブルの参加者を再度集め、ファシリテーター/SME が次の推奨ソリューションを共有するのを聞きます。

## 推奨される対象者

Peter Guerin 氏、World Wide Importers、最高技術責任者 (CTO)。

主な対象者は、ビジネス担当の意思決定者および技術担当の意思決定者です。ケース スタディのシナリオから、WWI の CTO の Peter Guerin 氏が含まれます。通常は、CIO (最高情報責任者) に直属のインフラストラクチャ マネージャー、アプリケーション スポンサー (LOB 担当 VP (基幹業務担当副社長)、CMO (最高マーケティング責任者) など)、あるいはアプリケーション スポンサー直轄の部署の IT 部門または開発者の代表者に話をします。

## 推奨ソリューション

アーキテクチャの概要

1. データ読み込み、データ変換、ストレージ、機械学習モデリング、およびレポートの最上位の要件に対応するための初期ビジョンを図示します。
   
   以下の図は、データ パイプライン アーキテクチャの "コールド パス" のプロセス概要を示しています。最初は、Oracle、SAP Hana、および Teradata の各ソースからデータを取り込みます。これは、Azure Synapse Analytics 内で \[Copy data\] アクティビティを含む Azure Synapse パイプラインを使用することによって実行でき、データは Azure Data Lake Gen2 に保存されます。データ レイクのデータを最初に調査する際、Azure Synapse SQL で T-SQL を使用するか、または Azure Synapse Spark でノートブックを使用すると、簡単に調査できます。
   
   準備段階で、グラフィカル デザイナーを使用していくつかのデータ準備タスクを実行することによって、\[Copy data\] アクティビティと同様に Synapse パイプラインのアクティビティである \[Mapping Data Flow\] を作成できます。この準備段階では、データが Parquet などの便利なフォーマットで確実に保存されるようにします。重複を排除し、誤りのあるデータをフィルターで除外し、不足している値を推定するために、初回のデータ クレンジングを実行します。
   
   次に、データはさまざまな方法で変換および強化できます。
   
   Azure Synapse SQL は、サーバーレスとプロビジョニング済みの両方のリソース モデルを提供しており、顧客のニーズに適合する利用オプションと課金オプションを提供します。パフォーマンスとコストを予測可能にするために、SQL テーブルに保存されているデータ用に処理能力を予約するためのプールをプロビジョニングします。一時的またはバースト的なワークロードには、常に利用可能なサーバーレス SQL エンドポイントを使用します。
   
   Azure Synapse Spark で動作するノートブックと同様に、Azure Synapse SQL プールおよび Azure Synapse SQL サーバーレス エンドポイントを使用して、T-SQL を使用する変換を適用できます。この段階で、データのクリーニング、結合、および強化を行い、最終的にデータ提供データベースとして動作する Azure Synapse SQL にデータを読み込む、反復可能なプロセスを定義するために、Synapse パイプラインも広く使用されています。
   
   データ提供レイヤーは、リレーショナル データ ウェアハウスからのデータまたはデータ レイクからのデータの両方を提供するために事前にプロビジョニングされた計算能力を提供する、専用の Azure Synapse SQL プールで構成できます。さらに、データ提供レイヤーは Azure Synapse SQL サーバーレスを使用して、データ レイクに保存されているデータに対してクエリを実行するための一時的な計算能力を提供できます。これらのデータ提供オプションのどちらも、Azure Synapse Analytics 内で作成した、または外部アプリケーションで作成した、Power BI レポートで使用できます。このアーキテクチャから、ここに示されているすべてのコンポーネントが Azure Synapse Analytics 内で完全に管理されているという重要な結論が得られます。
   
   ![上のテキストで説明している、データ パイプライン アーキテクチャの "コールド パス" のプロセス概要を示す図です。](media/preferred-solution.png "データ パイプライン アーキテクチャのコールド パス")
   
   以下の図は、"ホット パス" であるストリーミング データを処理する方法を示しています。Twitter のツイート データは、WebJob を使用して抽出する必要があります。この WebJob は、Stream Analytics を使用して確実に処理できるように、ツイートを Event Hubs に読み込みます。Stream Analytics は、Azure Synapse Analytics 内でプロビジョニングされている Azure Synapse SQL を使用したオフライン分析またはバッチ分析で使用するためにすべてのツイートをデータ レイクにアーカイブすることと、リアルタイム ダッシュボードおよびレポートに表示するためにライブ データを Power BI に送信することの両方に使用できます。店舗内 IoT センサーは、データを IoT Hub に直接取り込むことができ、さらに IoT Hub と統合することによって、IoT Hub によって実現されるデバイス管理機能を利用することもできます。このデータも、最終的には別の Stream Analytics ジョブによって処理され、ツイートと同じ方法で提供されます。
   
   ![上のテキストで説明している、"ホット パス" であるストリーミング データを処理するプロセスを示す図です。](media/preferred-solution-streaming.png "ストリーミング データに対するホット パスのアプローチ")
   
   以下の図は、機械学習に関して、Azure Synapse Analytics で WWI 向けに実現するアプローチを示しています。WWI は、Azure Machine Learning または Azure Synapse Spark 内で動作するノートブックを使用して、機械学習モデルをトレーニングできます。そのために使用する機械学習フレームワークは、WWI が選択できます。このノートブック内でモデルを ONNX 形式に変換してから、そのモデルを Azure Storage にアップロードします。そこから、Azure Synapse SQL で T-SQL スクリプトを実行して、モデルをデータベース内のテーブルに読み込みます。その後、テーブルからモデルをロードし、Predict 関数でモデルを使用してデータベース内のテーブルから供給されるデータにスコアを付けることによって、Azure Synapse SQL を実行する T-SQL スクリプト内でモデルを使用できます。スコアが付けられた結果は、直接使用することや、後で予測のクエリを実行するためにターゲット テーブルに挿入することができます。
   
   ![上のテキストで説明している機械学習アプローチを示す図です。](media/preferred-solution-machine-learning.png "機械学習に関する Azure Synapse Analytics モデル")

取り込みと保存

1. 推奨するソリューションについて、フラット ファイル データを、取り込んで保存した場所からデータ レイクに移動する最も効率的な方法は、具体的にはどのアプローチだと WWI に伝えますか。
   
   最初はデータ レイクにデータを保存するパターンに従い、次にフラット ファイルからデータ ウェアハウス内のリレーショナル テーブルに取り込む必要があります。ソース データを抽出して、Azure Data Lake Store Gen2 に Parquet ファイルとして保存するパイプラインを作成できます。

2. どのストレージ サービスを使用するように勧めますか。さまざまな洗練レベルでデータを管理できるようにするために、どのようにフォルダーを構造化することを勧めますか。
   
   Azure Data Lake Store (ADLS) Gen2 (階層ファイル システムを備えた Azure Storage) を使用する必要があります。
   
   ADLS でのベスト プラクティスは、運用専用のストレージ アカウントを用意し、それとは別に開発とテストのワークロード用のストレージ アカウントを用意することです。これにより、開発またはテストのワークロードが決して運用に干渉しないことが保証されます。
   
   一般的なフォルダー構造としては、洗練レベル別にフォルダーを分けてデータを整理する方法があります。たとえば、ブロンズ フォルダーには生データ、シルバー フォルダーにはクリーニング、準備、および統合を実施したデータを格納します。ゴールド フォルダーにはすぐに分析に使用できるデータを格納します。これには、計算前の集計など、最終的に洗練されたデータが含まれる場合があります。

3. 新しいデータ ソースからバッチで生データを取り込む場合、ソリューションではどのデータ形式をサポートできますか。
   
   CSV、Parquet、ORC、JSON をサポートできます。

4. 店舗内 IoT デバイスからのストリーミング データをどのように取り込みますか。
   
   メッセージを Event Hub または IoT Hub に収集して、Stream Analytics で処理する必要があります。

変換

1. 生データを取り込んだ後、変換パイプラインを構築する前またはそれをデータ ウェアハウスに読み込む前に、WWI はどのようにして速やかにその生データを調査してその内容を理解できるのでしょうか。
   
   Azure Synapse Studio を使用すると、ADLS に保存されている Parquet ファイルを右クリックして、SQL として、またはノートブックで DataFrame として、クエリを実行できます。

2. 洗練したバージョンのデータをクエリできるように保存する場合、どのデータ形式を使用することを勧めますか。それはなぜですか。
   
   Parquet を勧めます。(たとえば、Hadoop、Databricks、および SQL エンジンの各シナリオにわたって) ストレージ レイヤーでのデータ共有で Parquet 形式を使用することについて、業界で足並みを揃えています。Parquet は、高パフォーマンスの列指向形式であり、ビッグ データ シナリオに最適化されています。

3. データの準備、マージ、および変換に使用するように勧めるサービスについて、どの状況でグラフィカル デザイナーを使用できて、どの状況でコードを作成する必要がありますか。
   
   Azure Synapse Studio でグラフィカルに設計する場合は、マッピング データ フローを使用できます。これはコード不要のデータ フローであり、スケーラブルな実行が可能です。データ フローは変換用のドメイン固有の言語を定義し、それを Spark 上で動作するコードに変換します。このコードは、大規模に動作し、増え続けるデータ量に対応できる弾力性を提供します。
   
   データ エンジニアが Spark を使用してデータフレーム経由でデータを変換することを選択した場合は、コードを使用できます。

4. WWI のデータ チームは、データの速やかな前処理と、データ サイエンティストによる Spark と Python の両方を使用した機械学習モデルのトレーニングを可能にするオープン ソース パッケージを利用することに慣れています。マイクロソフトのソリューションでそれを実現する方法を説明してください。
   
   Azure Synapse Analytics は、オープン ソースの Apache Spark をサポートし、Python、Scala、および (近い将来) R のコードの実行をサポートしています。WWI のデータ チームは、使い慣れた Jupyter ノートブックを使用することや、お気に入りのライブラリを利用することができます。

5. マイクロソフトのソリューションでは、WWI のデータ エンジニアとデータ サイエンティストが Jupyter ノートブック内で作業できますか。ライブラリをどのように管理しますか。
   
   Azure Synapse Spark プールを使用すると、作成中にライブラリをインポートできます。
   
   ライブラリの依存関係は、必要なライブラリの名前とバージョンをリストした PIP freeze 形式のテキスト ドキュメントを使用して指定します。
   
   その後でデータ チームは Azure Synapse Spark プールにアタッチされているノートブックを起動して、お気に入りのライブラリを使用するコードを作成できます。

6. このソリューションは、サプライヤーの請求書によって、データ ウェアハウス内の部品コスト テーブルを常に更新する必要性にどのように対応しますか。
   
   WWI は、カスタム スキルとして、Form Recognizer サービスを呼び出す Azure Cognitive Search スキルセットと Synapse パイプラインを組み合わせることによってこれを達成できます。このパイプラインは、以下のように動作します。
   
   - 請求書が、Azure Storage にアップロードされます。
   - これにより、Synapse パイプラインがトリガーされます。
   - Synapse パイプラインには、Azure Cognitive Search スキルセットを呼び出す Web アクティビティが含まれています。
   - スキルセット内の最初のスキルは、Azure Function を呼び出し、PDF 請求書に対する URL を渡します。
   - Azure Function は、Form Recognizer サービスを呼び出し、PDF 請求書に対する URL と SAS トークンを渡します。Forms Recognizer は、OCR の結果をこの関数に返します。
   - Azure Function は、その結果をスキルセットに返します。次に、そのスキルセットは、製品名とコストのみを抽出し、構成ナレッジ ストアに送信します。このナレッジ ストアは、Azure Storage の JSON ファイルに、抽出されたデータを書き込みます。
   - Synapse パイプラインは、データ フロー アクティビティで Azure Storage から JSON ファイルを読み取り、Synapse SQL プール内の製品カタログ テーブルに対して更新/挿入 (upsert) を実行します。

クエリ

WWI の販売トランザクション データセットは 10 億行を超えています。ダウンストリームのレポート クエリのために、これらの行を数十秒以内で結合、射影、およびフィルターできるようにする必要があります。WWI は、これを実現するにはあまりにデータが多すぎることを懸念しています。

1. ファクト テーブルで前述のパフォーマンスを達成するには、具体的にどのインデックス作成手法を使用する必要がありますか。それはなぜですか。
   
   クラスター化列ストア インデックスを使用します。クラスター化列ストア インデックスは、データ圧縮と全体的なクエリ パフォーマンスが最も優れています。通常、ファクト テーブルのような大規模なテーブルには、列ストア インデックスが最適な選択肢です。

2. 1 億行未満のテーブルにも同じアプローチを勧めますか。
   
   いいえ。1 億行未満の "小さい" テーブルでは、ヒープ テーブルを検討する必要があります。

3. 小規模なルックアップ テーブル (店舗の名称や住所が保存されているテーブルなど) のインデックスはどのように構成する必要がありますか。
   
   ヒープ テーブルの使用を検討する必要があります。1 億行未満の小さなルックアップ テーブルでは、多くの場合、ヒープ テーブルが役立ちます。1 億行未満のクラスター化列ストア テーブルは、1 億行を超えて初めて最適な圧縮が実現されます。

4. 1 行のみを取得するポイント ルックアップにのみ使用する大規模なルックアップ テーブルにはどんなことを提案しますか。複数のクエリがフィルタリングする列が異なっていても効率的にルックアップできるように、大規模なルックアップ テーブルの柔軟性を高めるにはどうすればいいですか。
   
   クラスター化インデックスを使用します。1 つの行をすばやく取得する必要がある場合に、クラスター化インデックスは、クラスター化列ストア テーブルより優れている可能性があります。1 行または極めて少数の行の検索を極めて高速で実行する必要があるクエリの場合、クラスター化インデックスまたは非クラスター化セカンダリ インデックスを検討します。
   
   クラスター化インデックスを使用するデメリットは、効果が得られるのが、クラスター化インデックス列で非常に選択的なフィルターを使用するクエリのみに限定されることです。他の列のフィルター パフォーマンスを改善するには、非クラスター化インデックスを他の列に追加できます。
   
   ただし、テーブルにインデックスを 1 つ追加するたびに、データを読み込むための領域が増えて、処理時間が長くなることに注意します。

5. ステージング テーブルの読み込みを最も速くするには、何を使用する必要がありますか。
   
   ヒープ テーブルを使用します。さまざまな変換を実行する前にデータをステージングするためにのみ読み込む場合は、ヒープ テーブルにテーブルを読み込むと、データをクラスター化列ストア テーブルに読み込む場合よりもはるかに高速で読み込まれます。
   
   一時テーブルを使用します。テーブルを永続記憶域に読み込むよりも、データを一時テーブルに読み込んだ方が読み込みが速くなります。

6. 以下に示すシナリオでの**分散**テーブル設計に関して注意する必要がある典型的な問題には何がありますか。
   
   - 最も小さいファクト テーブルが数 GB を超えていて、本質的に挿入が頻繁に行われます。
     
     ハッシュ分散を使用する必要があります。
     
     ハッシュ分散テーブルは、決定論的なハッシュ関数を使用して各行を 1 つのディストリビューションに割り当て、複数のコンピューティング ノードにわたってテーブル行を分散させます。
     
     同一値は常に同じディストリビューションにハッシュされるため、データ ウェアハウスには行の位置情報に関する組み込みのナレッジがあります。SQL Data Warehouse ではこのナレッジを使用して、クエリ時のデータ移動を最小化し、クエリ パフォーマンスを向上させます。
     
     ハッシュ分散テーブルは、スター スキーマにある大規模なファクト テーブルに適しています。非常に多数の行を格納し、その上で高度なパフォーマンスを実現できます。
     
     ハッシュ分散テーブルの使用は、次の場合に検討してください。
     
     - ディスク上のテーブル サイズが 2 GB を超えている。
     - テーブルで、頻繁な挿入、更新、削除操作が行われる。
   
   - WWI のデータ チームは、データ ウェアハウスを開発する際に生の入力データから役に立つかもしれないテーブルをいくつか作成しましたが、現在それらのテーブルは他のテーブルと結合されておらず、データ分散に使用するのに最適な列も不明です。
     
     - ラウンド ロビンによる分散を検討する必要があります。
       
       ラウンド ロビン分散テーブルは、すべてのディストリビューションにわたって均等にテーブル行を分散させます。ディストリビューションに対する行の割り当てはランダムです。ハッシュ分散テーブルとは異なり、同じ値を持つ行が必ず同じディストリビューションに割り当てられるわけではありません。
       
       その結果、クエリを解決するために、システムでデータの移動操作を呼び出して、データを整理することが必要になる場合があります。この特別な手順のために、クエリが遅くなる可能性があります。ラウンド ロビン テーブルを結合する場合、通常は行を再度シャッフルする必要があり、パフォーマンスの低下につながります。
       
       次のシナリオでは、テーブルにラウンド ロビンによる分散を使用することを検討してください。
       
       - 既定になっているので、作業開始時の単純な始点とする場合
       - 明確な結合キーが存在しない場合
       - テーブルをハッシュ分散するのに適した候補列がない場合
       - テーブルが共通の結合キーを他のテーブルと共有していない場合
       - 結合がクエリの他の結合ほど重要ではない場合
       - テーブルが一時ステージング テーブルである場合
   
   - WWI のデータ エンジニアは、データを準備する際に、一時ステージング テーブルを使用することがあります。
     
     ラウンド ロビン分散テーブルを使用する必要があります。
   
   - 数百 MB から 1.5 GB までの規模のルックアップ テーブルがあります。
     
     レプリケート テーブルの使用を検討する必要があります。レプリケート テーブルには、各コンピューティング ノード上でアクセスできるテーブルの完全なコピーがあります。テーブルをレプリケートすると、結合または集計の前に、コンピューティング ノード間でデータを転送する必要がなくなります。テーブルには複数のコピーが含まれているため、テーブルのサイズが 2 GB 未満に圧縮されている場合にレプリケート テーブルが最も効果的に機能します。

7. データの一部に JSON 形式の列が含まれています。どうすればこれらの階層フィールドを表形式構造に平坦化できますか。
   
   Azure Synapse SQL サーバーレスを、T-SQL OPENJSON、JSON\_VALUE、および JSON\_QUERY の各ステートメントと組み合わせて使用できます。

8. JSON データを更新するのにどんなアプローチを使用できますか。
   
   UPDATE ステートメントで JSON\_MODIFY を使用できます。

9. WWI は、一部のクエリでは、結果を返す時間を短縮できるのであれば、精度が多少落ちるのは構わないと考えています。どうすればそれを実現できますか。
   
   APPROXIMATE\_COUNT\_DISTINCT ステートメントを使用する必要があります。これは、HyperLogLog を使用して、平均で誤差が 2% のカーディナリティの結果を返します。たとえば、COUNT(DISTINCT) が 1,000,000 を返す場合、概算の実行を使用すると、999,736 ～ 1,016,234 の値が返されます。

10. ダウンストリームのレポートは多数のユーザーが使用します。これは多くの場合、それほど頻繁に変化しないデータに対して同じクエリが繰り返し実行されることを意味します。何を使用すると、このようなタイプのクエリのパフォーマンスを高めることができますか。基礎となるデータが変化する場合、このアプローチはどのように機能しますか。
    
    結果セットのキャッシュを検討する必要があります。
    
    Azure Synapse SQL プール ストレージをプロビジョニングして、そこにクエリの結果をキャッシュします。これにより、データが頻繁に変更されないテーブルに対して繰り返し実行するクエリで、インタラクティブな応答時間が実現します。
    
    Azure Synapse SQL プールが一時停止した後に再開された場合でも、結果セットのキャッシュは維持されます。
    
    基礎となるテーブルのデータやクエリ コードが変更されると、クエリのキャッシュは無効になり、更新されます。
    
    結果のキャッシュは、Time Aware Least Recently Used (TLRU) アルゴリズムに基づいて定期的に削除されます。

可視化

1. WWI は、どの製品を使用すると、小売トランザクション データを可視化できますか。それはインストールする必要がある独立したツールですか。
   
   Power BI を使用します。Azure Synapse Studio 内で直接、Power BI レポートを作成、編集、および表示できます。また、Power BI Desktop を使用して、データセットとレポートの両方を作成および公開して、ワークスペース内で使用できるようにすることが可能です。

2. その同じツールを使用して、バッチ データとストリーミング データの両方を 1 つのダッシュボード画面で可視化できますか。
   
   はい。Power BI を使用して、両方の種類のデータを可視化するダッシュボードを作成できます。

3. 推奨する製品を使用する場合、データを参照するレポートを作成する前に、すべてのデータをデータ ウェアハウスに読み込む必要がありますか。
   
   いいえ。必要なのは、Azure Storage にデータを読み込むことだけです。Azure Synapse SQL サーバーレスと Power BI を使用して、直接そのデータを使用するレポートを作成できます。

管理

1. これまで、WWI のシステムはユーザーに人気がありませんでした。時間的制約のない調査クエリが使用可能なリソースを飽和状態にして、重要なレポートを作成するための優先度の高いクエリの実行を遅らせていました。推奨するソリューションがこれを解決するのにどのように役立つのか説明してください。
   
   WWI は、Azure Synapse Analytics で、この状況を防ぐのに役立つワークロード管理を構成する必要があります。
   
   ワークロード管理は、リソースを管理して、極めて効率的なリソース利用を保証し、投資収益率 (ROI) を最大化します。
   
   ワークロード管理の 3 本の柱を以下に示します。
   
   - ワークロードの分類: 要求をワークロード グループに割り当てて、重要度レベルを設定します。
   - ワークロードの重要度: 要求がリソースにアクセスする順序に影響します。
   - ワークロードの分離: ワークロード グループ用にリソースを予約します。

2. 推奨するソリューションは、テーブル分散が最適ではない、データ スキュー、キャッシュ ミス、tempdb 競合、プラン選択が最適ではないなどの問題を WWI が検出するのを支援するために何を提供しますか。
   
   Azure Advisor からのレコメンデーションを利用できます。

3. WWI は、データ ウェアハウス ソフトウェアを最新の状態に保つには、それに伴うダウンタイムを許容できるタイミングを決める必要があることを理解しています。推奨するソリューションでは、どうすれば WWI は予期しないアップグレードに慌てることのない設定を確立できますか。
   
   Azure Synapse Analytics の機能であるメンテナンス ウィンドウを利用する必要があります。この機能では、以下のことを実行できます。
   
   - アップグレードのための時間枠を選択する。
   - 7 日間の期間内でプライマリ時間枠とセカンダリ時間枠を選択する (各時間枠は 3 ～ 8 時間の範囲で設定可能)。
   - メンテナンス イベントの通知を 24 時間前に受け取る。

安全性

1. 推奨するソリューションは、たとえば SQL と Spark のワークロードに対して、どのようにして統合された認証を提供しますか。
   
   Azure Synapse Analytics は、Azure Active Directory (AAD) をその認証メカニズムとして使用します。ユーザーが Azure Synapse Analytics ワークスペースにログインする際、プロビジョニング済み Azure Synapse SQL プールで T-SQL クエリを実行するため、Azure Synapse Spark プールでノートブックを実行するため、および Power BI レポートにアクセスするために、アクティブ ユーザーの AAD 資格情報が暗黙的に使用されます。この AAD 資格情報は、Azure Synapse SQL データベースまたは Azure Storage の階層ファイル システム (Azure Data Lake Store Gen2 または ADLS Gen2) に保存されているデータへのアクセスを制御する際にも利用されます。Azure Synapse Analytics は、AAD を利用することで、ユーザー ID を一元管理できます。

2. Azure Data Lake Store Gen2 に保存されているデータに対するデータ アクセスをどのように承認しますか。Azure Synapse SQL データベースに保存されているデータについてはどうですか。
   
   **ADLS Gen2 での承認:** 承認の観点から言えば、Azure Storage のコンテナー レベルで AAD ロールを指定することによって粗いアクセス制御を適用できます。さらに、フォルダー レベルで POSIX ACL を設定することによって、きめ細かいアクセス制御が実現します。
   
   **データベースでの承認:** データベースのアクセス許可の管理は、Azure Active Directory のグループとユーザーにアクセス許可を設定することによって実行しますが、これらはデータベースの外部に存在します。オブジェクト レベルのセキュリティでは、テーブル、ビュー、ストアド プロシージャ、および関数に対するアクセス許可を制御できます。

3. WWI の課題の 1 つは、複数の部門が特定のテーブルに対するクエリを実行できる可能性がある一方で、各自にどのデータの表示が許可されるのかは部門または社内での役割によって決まることです。推奨するソリューションでは、これをどのようにサポートできますか。3 つの選択肢を提案する必要があります。
   
   これは、行レベルのセキュリティ、列レベルのセキュリティ、または動的データ マスクを使用するさまざまな方法で達成できます。ニーズに応じて同じテーブルに 3 つすべてを適用してもメリットを得られる可能性があります。
   
   **行レベルのセキュリティ:** Azure Synapse Analytics では、Azure Synapse SQL データベースのテーブルは、行レベルのセキュリティ (RLS) をサポートしています。RLS により、データ行アクセスの制限を実装できます。アクセス制限のロジックは、別のアプリケーション層のデータから切り離されず、データベース層に配置されるため、任意の層からデータへのアクセスが試行されるたびに、データベース システムにアクセス制限が適用されます。RLS は、ユーザーが選択、更新、または削除することを承認されていない行を実質的にフィルターで除外すると考えてください。これにより、セキュリティ システムの攻撃対象領域を減少させることで、セキュリティ システムがより信頼性の高い堅牢なものになります。
   
   **列レベルのセキュリティ:** Azure Synapse SQL データベースのテーブルは、列レベルのセキュリティ (CLS) もサポートしています。CLS は、ユーザーのグループ メンバーシップまたは実行コンテキストに基づいて、データベース テーブルの特定の列へのアクセスを制御できます。
   
   **動的データ マスク:** もう 1 つの方法として、ユーザーのグループ メンバーシップに従ってフィールドの一部のみを表示する必要がある場合 (電子メール アドレスを数文字だけ表示する場合など)、動的データ マスクを使用できます。

4. そのソリューションは、WWI がセキュリティの構成ミスを検出、追跡、および修復し、脅威を検出するのに役立ちますか。どんな方法ですか。
   
   主に、SQL の脆弱性評価と SQL の脅威検出の 2 つの方法があります。
   
   SQL の脆弱性評価は、データベースの潜在的な脆弱性の検出、追跡、および修復に役立つ、使いやすいサービスです。データベースのセキュリティの状態を可視化し、継続的な改善を可能にします。簡単に言うと、以下のことを実行します。
   
   - セキュリティの構成ミスを特定する一連のセキュリティ チェックを実行します。
   - 顧客環境に合わせて結果をカスタマイズするセキュリティ ベースラインを設定できます。
   - セキュリティ監査に非常に役立つクリア レポートを提供します。
   
   SQL 脆弱性評価は、Azure Portal から実行します。ほんの数秒で実行でき、完全に読み取り専用で動作します。データベースに対する変更は一切行われません。
   
   スキャンが完了すると、レポートが表示されます。レポートには、セキュリティ状態、検出された問題の数、およびそれぞれの重要度の概要が表示されます。結果には、ベスト プラクティスからの逸脱に対する警告に加えて、データベースのプリンシパルとロールおよびそれらに関連付けられているアクセス許可など、セキュリティ関連の設定のスナップショットが含まれます。スキャン レポートでは、データベースで検出された機密データのマップや、機密データを保護するために使用可能な組み込まれている手法のお勧めも提供されます。
   
   このレポートから、不合格の各結果について詳細を確認して、検出内容の影響について理解し、各セキュリティ チェックの不合格理由を把握できます。レポートで提供される実用的な修復情報を使用して、たとえば、生成された修復スクリプトを新しいクエリ エディタ ウィンドウで実行するなどの方法で、問題を解決できます。
   
   評価結果を確認する際、特定の結果に、環境内で許容可能なベースラインであるとしてマークを付けることができます。このベースラインの本質は、結果を報告する方法のカスタマイズです。ベースラインと一致する結果は、それ以降のスキャンで合格と見なされます。
   
   SQL の脅威検出を使用すると、潜在的な SQL インジェクション攻撃、異常なアクセス、データ流出などのアクティビティを検出することや、調査および修復のための実用的なアラートをメールで送信することなどの方法で、データベースを侵害しようとする異常で有害な試みに対応できます。この構成は、Azure Portal で行います。

5. WWI はこのソリューションを使用して、機密情報を検出、分類、および保護し、機密情報へのアクセスを追跡できるようにすることで、機密情報を監視できますか。
   
   はい。SQL データの検出と分類を使用して、以下を実行します。
   
   - 潜在的な機密データを含む列を自動検出します。
   - Azure Portal を通じて分類の推奨事項をレビューして適用する簡単な方法を提供します。
   - 機密データ ラベルを (メタデータ属性として) データベースに保持し、機密データへのアクセスを監査および検出します。一連のラベルと情報タイプが組み込まれていますが、ユーザーが Azure Security Center を使用して Azure テナント全体で使用するカスタム ラベルを定義することもできます。
   - この機能には、Azure Portal からアクセスします。

6. ネットワーク セキュリティの観点から、推奨するソリューションをどのように保護する必要がありますか。
   
   WWI は、マネージド ワークスペース仮想ネットワーク (VNet) 内に Azure Synapse Analytics ワークスペースを展開した後、マネージド プライベート エンドポイントを使用して Azure リソースへのプライベート リンクを確立する必要があります。プライベート リンクを使用することによって、VNet と Azure Synapse Analytics ワークスペースの間のトラフィックが完全に Microsoft バックボーン ネットワーク上で伝送されるので、データ流出リスクから保護されます。リソースへのプライベート リンクは、プライベート エンドポイントを作成することによって確立します。プライベート エンドポイントは、VNet から取得するプライベート IP アドレスを使用して、実質的にサービスを VNet に "持ち込み" ます。Azure Synapse Analytics は、マネージド VNet 内で Azure Synapse ワークスペースが作成される際、自動的に 2 つのマネージド プライベート エンドポイントを作成します。

## 反論への推奨される対応のチェックリスト

1. WWI は、Azure が提供するいくつかのサービスでは機能が重複していることを把握しています。望んでいる分析ソリューションになるように、時間をかけてそれらを調整したいとは考えていません。
   
   - Azure Synapse Analytics は、まさにこの状況に対応するように設計されており、顧客が異種サービスを接続するプラミング インフラストラクチャに時間を費やすことなく、速やかに分析からビジネス価値を創造できるようにします。

2. 大量のデータセットを数秒以内で読み込むと主張する競合システムのデモを見たことがあります。Azure ではそのようなソリューションを提供していますか。
   
   - Azure Synapse Analytics は、この課題に対するマイクロソフトの答えであり、大量のデータセットの高速読み込みをサポートするよう設計されています。

3. 取り込み、変換、クエリ、および保存を行う際に使用する異種サービスの数を最小限に抑えて、WWI のデータ エンジニア、データ サイエンティスト、およびデータベース管理者から成るチームが、1 つのツールを習得し、開発、管理、および監視を行うための共有ベスト プラクティスを構築できるようにすることが本当に可能ですか。
   
   - はい。Azure Synapse Analytics は、まさにこれを実行するための統合環境を提供します。

4. サーバーレス クエリのことを聞いたことがありますが、Azure では提供していますか。それは WWI が持つ規模のデータのクエリに対応できますか。どの形式をサポートしていますか。WWI のダッシュボードやレポートをサポートするのに適していますか。
   
   - Azure Synapse Analytics は、サーバーレス SQL エンドポイント経由のサーバーレス クエリをサポートします。
   - Azure Synapse SQL サーバーレスは、Azure Storage 内の大量データに対する T-SQL クエリを提供する、常に使用可能な SQL エンドポイントであり、一時的またはバースト的なワークロードに最適です。
   - さまざまな形式 (Parquet、CSV、JSON) のデータをサポートします。
   - Power BI をサポートし、ダッシュボードのデータセットの更新に使用できるので、ダッシュボードとレポートに適しています。基本的なデータの検出と調査にも適しており、大規模な並列処理で Azure Storage ベースのデータを変換する "単一クエリ ETL" をサポートしています。

5. Azure がサーバーレス クエリをサポートしている場合、サーバーレスを選択すると、事前に割り当てたクエリ リソースを使用するオプションは削除されますか。
   
   - いいえ。これは、Azure Synapse Analytics に固有の差別化要因です。1 つの Azure Synapse Analytics ワークスペース内に、事前にプロビジョニングした Azure Synapse SQL プールを配置して、さらに Azure Synapse SQL サーバーレス エンドポイントを使用するサーバーレス クエリも配置することができます。

6. 保存時のデータは保護されますか。データの暗号化に使用した鍵の管理は行われますか。
   
   - Azure Synapse SQL データベースに保存されているデータおよび Azure Storage (Azure Data Lake Store Gen2 を含む) に保存されているデータに対して、Azure Synapse Analytics は Transparent Data Encryption (TDE) をサポートします。これは、すべてのデータは、ディスクに書き込まれるときに暗号化され、ディスクから読み取られるときに復号されることを意味します。暗号化と復号に使用される鍵に関して言えば、TDE は、マイクロソフトが提供するサービス管理キーまたは顧客が提供して Azure Key Vault に安全に保存されるユーザー管理キーを使用するオプションを提供します。

7. Azure Databricks と Azure Synapse Analytics は機能が重複しているように見えますが、何を基準にして選択するのですか。
   
   - 主にデータ ウェアハウス ソリューションを探している顧客には、Azure Synapse Analytics をお勧めします。
   - 主に Spark ソリューションを探していて、データ ウェアハウスのニーズがない顧客には、Azure Databricks をお勧めします。Spark ベースの ML シナリオの場合、実験の追跡、自動機械学習、および MLOps には、Azure Databricks の Azure Machine Learning を使用することをお勧めします。
   - Spark に多額の投資を行っていて、データ ウェアハウスのニーズがある顧客には、Azure Databricks と Azure Synapse の両方をお勧めします。

8. Azure は、クライアント アプリケーションから簡単に呼び出すことができるように、Web サービスとしてのモデルの展開をどのようにサポートしていますか。モデルは、Web サービスとしてどのように展開されますか。
   
   ソリューション内の Azure Machine Learning を使用すると、WWI は、ソリューション内の他の場所でモデルのトレーニングを行い、Azure Kubernetes Service または Azure Container Instances にホストされる REST Web サービスとしてモデルを展開することができます。また、Azure Machine Learning SDK を使用して、AKS から Web サービスを展開することができます。一般に、モデルを展開するには、Web サービスのロジックを含むスコアリング Web サービス スクリプトを作成する必要があります。このスクリプトは、ディスクからモデルを読み込み、スコアリングのためにそのモデルを使用し、スコアが付けられた結果を返します。Azure Machine Learning モデル レジストリと統合すると、スコアリング スクリプトは、Web サービスを最初に開始したときに、Azure Machine Learning モデル レジストリから直接、最新のモデルを自動的に取り込むことができます。これにより、必要に応じて、Web サービスで常に最新のモデルを使用することができます。この方法で展開される Web サービスは、Swagger OpenAPI エンドポイントを公開するように構成することができます。これによって、開発者が自動生成されたドキュメンテーションを提供し、開発者ツールを使用して Web サービスを実行するためのクライアント ライブラリを作成することが容易になります。

9. Azure において、モデルの再トレーニング プロセスはどのように実行されますか。WWI のデータ サイエンティストは、新しいモデルをトレーニングし、評価する一方で、アプリケーションに更新を展開するために使用される DevOps プロセスに、どのようにこの再トレーニングを確実に組み込むことができますか。Azure は、クライアント アプリケーション、機械学習 API、およびその API を支援するモデルに対する更新を調整するために役立ちますか。
   
   モデルの再トレーニング プロセスは、MLOps と呼ばれるアプローチで DevOps プロセス内にすべて統合できます。このアプローチでは、Azure DevOps が利用されます。全体的なアプローチは、Azure DevOps から Azure パイプラインの継続的な統合と継続的な提供を調整することです。これらのパイプラインは、Azure Machine Learning SDK で作成される Machine Learning パイプラインを記述する成果物の変更によってトリガーされます。たとえば、モデル トレーニング スクリプトの変更をチェックインすると、Azure Pipelines ビルド パイプラインが実行されます。これは、モデルをトレーニング (または再トレーニング) し、コンテナー イメージを作成します。次に、Azure Pipelines リリース パイプラインがトリガーされて、ビルド パイプラインで作成された Docker イメージを使用して、Web サービスとしてモデルを展開します。実稼働後に、スコアリング Web サービスは、Application Insights と Azure Storage の組み合わせを使用して監視されます。このアプローチにより、展開パイプラインを再実行して、ソリューションのあらゆるコンポーネント、再トレーニングされた包含モデルを更新することができます。

## 顧客の声 (最後に出席者に対して読み上げる)

「マイクロソフトの Azure Synapse Analytics で目的を達成しました。弊社が求めていたスケーラブルで高パフォーマンスな統合分析ソリューションを導入することができて、全店舗にわたってビジネスを目覚ましく改善できました。」

-- Peter Guerin 氏、World Wide Importers、最高技術責任者 (CTO)。